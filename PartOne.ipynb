{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imported libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import math\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 20000000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4788bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part A:Read Novels \n",
    "def read_novels(path=Path.cwd() / \"texts\" / \"novels\"):\n",
    "    \"\"\"Reads texts from a directory of .txt files and returns a DataFrame with the text, title,\n",
    "    author, and year\"\"\"\n",
    "    texts = []\n",
    "    titles = []\n",
    "    authors = []\n",
    "    years = []\n",
    "\n",
    "    for file in path.glob(\"*.txt\"):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            texts.append(text)\n",
    "\n",
    "            filename = file.stem\n",
    "            title, author, year = filename.split('-')\n",
    "\n",
    "            titles.append(title.replace('_', ' '))\n",
    "            authors.append(author)\n",
    "            years.append(int(year))\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        \"text\": texts,\n",
    "        \"title\": titles,\n",
    "        \"author\": authors,\n",
    "        \"year\": years\n",
    "    })\n",
    "    \n",
    "    df = df.sort_values('year').reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B: type-token ratio (TTR)\n",
    "def nltk_ttr(df):\n",
    "    \"\"\"Calculates the type-token ratio of a text. Returns a mapped dictionary title -> TTR.\"\"\"\n",
    "    ttr_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        tokens = word_tokenize(row['text'])\n",
    "        words = [word.lower() for word in tokens if word.isalpha()]\n",
    "        types = set(words)\n",
    "        ttr = len(types) / len(words) if len(words) > 0 else 0\n",
    "        ttr_dict[row['title']] = ttr\n",
    "\n",
    "    return ttr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72943d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part C: Flesch-Kincaid Grade Level\n",
    "def count_syl(word, d):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        word (str): The word to count syllables for.\n",
    "        d (dict): A dictionary of syllables per word.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of syllables in the word.\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    if word in d:\n",
    "        return len([syl for syl in d[word][0] if syl[-1].isdigit()])\n",
    "    else:\n",
    "        vowels = \"aeiouy\"\n",
    "        syllable_count = 0\n",
    "        prev_char_was_vowel = False\n",
    "        \n",
    "        for char in word:\n",
    "            if char in vowels:\n",
    "                if not prev_char_was_vowel:\n",
    "                    syllable_count += 1\n",
    "                    prev_char_was_vowel = True\n",
    "            else:\n",
    "                prev_char_was_vowel = False\n",
    "        \n",
    "        if word.endswith('e') and syllable_count > 1:\n",
    "            syllable_count -= 1\n",
    "\n",
    "        return max(syllable_count, 1) \n",
    "\n",
    "def flesch_kincaid(df):\n",
    "    \"\"\"Returns the Flesch-Kincaid Grade Level of a text (higher grade is more difficult).\n",
    "    Requires a dictionary of syllables per word.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing the text to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping titles to their Flesch-Kincaid Grade Level.\n",
    "    \"\"\"\n",
    "    d = cmudict.dict()\n",
    "    fk_dict = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        sentences = sent_tokenize(text)\n",
    "        words = [w for w in word_tokenize(text) if w.isalpha()]\n",
    "        \n",
    "        num_sentences = len(sentences)\n",
    "        num_words = len(words)\n",
    "        num_syllables = sum(count_syl(word, d) for word in words)\n",
    "        \n",
    "        if num_words > 0 and num_sentences > 0:\n",
    "            fk_grade_level = (0.39 * (num_words / num_sentences)) + (11.8 * (num_syllables / num_words)) - 15.59\n",
    "            fk_dict[row['title']] = fk_grade_level\n",
    "        else:\n",
    "            fk_dict[row['title']] = 0\n",
    "\n",
    "    return fk_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part E: parse text with spaCy \n",
    "def parse(df, store_path=Path.cwd() / \"pickles\", out_name=\"parsed.pkl\"):\n",
    "    \"\"\"Parses the text of a DataFrame using spaCy, stores the parsed docs as a column and writes \n",
    "    the resulting  DataFrame to a pickle file\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the text to parse.\n",
    "        store_path (Path): Path to store the pickle file.\n",
    "        out_name (str): Name of the output pickle file.\n",
    "        Returns:\n",
    "        pd.DataFrame: The original DataFrame with an additional 'parsed' column containing spaCy Doc objects.\n",
    "        \"\"\"\n",
    "    \n",
    "    df['parsed'] = df['text'].apply(nlp)\n",
    "\n",
    "    with open(store_path / out_name, 'wb') as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b490be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part E: Load parsed DataFrame from pickle\n",
    "def load_parsed(store_path=Path.cwd() / \"pickles\", in_name=\"parsed.pkl\"):\n",
    "    \"\"\"Loads a parsed DataFrame from a pickle file\"\"\"\n",
    "    with open(store_path / in_name, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part F: Working with parses: \n",
    "def objects_most_common(doc):\n",
    "    \"\"\"The title of each novel and a list of the ten most common syntactic objects overall in the text.\"\"\"\n",
    "    objects = []\n",
    "    for token in doc:\n",
    "        if token.dep_ in ('dobj', 'iobj'):\n",
    "            objects.append(token.lemma_.lower())\n",
    "    return Counter(objects).most_common(10)\n",
    "\n",
    "\n",
    "def subjects_by_verb_count(doc, verb):\n",
    "    \"\"\"\n",
    "    The title of each novel and a list of the ten most common syntactic subjects of \n",
    "    the verb ‘to hear’ (in any tense) in the text, ordered by their frequency\n",
    "    \"\"\"\n",
    "    subjects = []\n",
    "    for token in doc:\n",
    "        if token.dep_ in ('nsubj', 'nsubjpass') and token.head.lemma_.lower() == verb.lower():\n",
    "            subjects.append(token.lemma_.lower())\n",
    "    return Counter(subjects).most_common(10)\n",
    "    \n",
    "\n",
    "\n",
    "def subjects_by_verb_pmi(doc, target_verb):\n",
    "    \"\"\"\n",
    "    The title of each novel and a list of the ten most common syntactic subjects of \n",
    "    the verb ‘to hear’ (in any tense) in the text, ordered by their Pointwise Mutual Information\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
